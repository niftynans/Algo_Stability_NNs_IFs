{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dying-cedar",
   "metadata": {},
   "source": [
    "## Credits: Matthew Mcateer -- https://matthewmcateer.me/blog/basics-of-influence-functions/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "incorporate-region",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# import tensorflow as tf\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "import numpy as np\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "received-bankruptcy",
   "metadata": {},
   "source": [
    "## Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "otherwise-assignment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LinearModel:\n",
    "    \n",
    "#     def __init__(self, data, target):\n",
    "#         self.data = data\n",
    "#         self.target = target\n",
    "#         self._prediction = None\n",
    "#         self._optimize = None\n",
    "#         self._error = None\n",
    "#         self._gradients = None\n",
    "#         self._hessians = None\n",
    "#         self._params = None\n",
    "        \n",
    "#     @property\n",
    "#     def params(self):\n",
    "#         if  self._params is  None:\n",
    "#             data_dim = int(self.data.get_shape()[1])\n",
    "#             target_dim = int(self.target.get_shape()[1])\n",
    "#             # we construct one variable for both weight and bias\n",
    "#             self._params = tf.get_variable(name='params', shape=[data_dim+target_dim])\n",
    "#         return  self._params\n",
    "\n",
    "#     @property\n",
    "#     def prediction(self):\n",
    "#         if  self._prediction is  None:\n",
    "#             data_dim = int(self.data.get_shape()[1])\n",
    "#             W = tf.reshape(self.params[:-1], [data_dim,1])\n",
    "#             b = self.params[-1]\n",
    "#             self._prediction = tf.matmul(self.data, W) + b\n",
    "#         return  self._prediction\n",
    "\n",
    "#     @property\n",
    "#     def error(self):\n",
    "#         if  self._error is  None:\n",
    "#             self._error = tf.losses.mean_squared_error(labels = self.target,\n",
    "#             predictions = self.prediction)\n",
    "#         return  self._error\n",
    "    \n",
    "#     @property\n",
    "#     def optimize(self, lr  =  0.1):\n",
    "#         if  self._optimize is  None:\n",
    "#             train_op = tf.train.GradientDescentOptimizer(learning_rate=lr).minimize(self.error)\n",
    "#             self._optimize = train_op\n",
    "#         return  self._optimize\n",
    "\n",
    "#     @property\n",
    "#     def  gradients(self):\n",
    "#         if  self._gradients is  None:\n",
    "#             self._gradients = tf.gradients(self.error, self.params)\n",
    "#         return  self._gradients\n",
    "\n",
    "#     @property\n",
    "#     def  hessians(self):\n",
    "#         if  self._hessians is  None:\n",
    "#             self._hessians = tf.hessians(self.error, self.params)\n",
    "#         return  self._hessians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "excited-eligibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModel:\n",
    "    \n",
    "    def __init__(self, data, target):\n",
    "        self.data = data\n",
    "        print(\"Init-Data: \", data)\n",
    "        self.target = target\n",
    "        print(\"Init-Target: \", target)\n",
    "        self._prediction = None\n",
    "        self._optimize = None\n",
    "        self._error = None\n",
    "        self._gradients = None\n",
    "        self._hessians = None\n",
    "        self._params = None\n",
    "        \n",
    "    @property\n",
    "    def params(self):\n",
    "        if  self._params is  None:\n",
    "            data_dim = int(self.data.get_shape()[1])\n",
    "            print(\"Params-data_dim: \", data_dim)\n",
    "            target_dim = int(self.target.get_shape()[1])\n",
    "            print(\"Params-target_dim: \", target_dim)\n",
    "            # we construct one variable for both weight and bias\n",
    "            self._params = tf.get_variable(name='params', shape=[data_dim+target_dim])\n",
    "            print(\"Params-total_dim: \", data_dim + target_dim)\n",
    "        return  self._params\n",
    "\n",
    "    @property\n",
    "    def prediction(self):\n",
    "        if  self._prediction is  None:\n",
    "            data_dim = int(self.data.get_shape()[1])\n",
    "            print(\"Prediction-data_dim: \", data_dim)\n",
    "            W = tf.reshape(self.params[:-1], [data_dim,1])\n",
    "            print(\"Prediction-W: \", W)\n",
    "            b = self.params[-1]\n",
    "            print(\"Prediction-b: \", b)\n",
    "            self._prediction = tf.matmul(self.data, W) + b\n",
    "        return  self._prediction\n",
    "\n",
    "    @property\n",
    "    def error(self):\n",
    "        if  self._error is  None:\n",
    "            self._error = tf.losses.mean_squared_error(labels = self.target,\n",
    "            predictions = self.prediction)\n",
    "            print(\"error-self._error: \", self._error)\n",
    "        return  self._error\n",
    "    \n",
    "    @property\n",
    "    def optimize(self, lr  =  0.1):\n",
    "        if  self._optimize is  None:\n",
    "            train_op = tf.train.GradientDescentOptimizer(learning_rate=lr).minimize(self.error)\n",
    "            self._optimize = train_op\n",
    "            print(\"optimize-self._optimize: \",self._optimize)\n",
    "        return  self._optimize\n",
    "\n",
    "    @property\n",
    "    def  gradients(self):\n",
    "        if  self._gradients is  None:\n",
    "            self._gradients = tf.gradients(self.error, self.params)\n",
    "            print(\"gradients-self._gradients\", self._gradients)\n",
    "        return  self._gradients\n",
    "\n",
    "    @property\n",
    "    def  hessians(self):\n",
    "        if  self._hessians is  None:\n",
    "            self._hessians = tf.hessians(self.error, self.params)\n",
    "            print(\"hessians-self._hessians: \",self._hessians)\n",
    "        return  self._hessians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "least-worthy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def  true_function(x, noise  =  True):\n",
    "    y = -5*x+5\n",
    "    if noise:\n",
    "        y += np.random.normal(scale=0.1, size = x.shape)\n",
    "    return y\n",
    "\n",
    "X_data = np.arange(-5,5,0.5).reshape((-1,1))\n",
    "Y_data = true_function(X_data) # linear function\n",
    "#perturbation\n",
    "Y_data[1] = 100.0\n",
    "Y_data[-5] = 100.0\n",
    "Y_data = Y_data.reshape((-1,1))\n",
    "X_test = 3.2*np.ones((1,1))\n",
    "Y_test = true_function(X_test, noise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "southern-cooperative",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init-Data:  Tensor(\"Placeholder:0\", shape=(?, 1), dtype=float32)\n",
      "Init-Target:  Tensor(\"Placeholder_1:0\", shape=(?, 1), dtype=float32)\n",
      "Prediction-data_dim:  1\n",
      "Params-data_dim:  1\n",
      "Params-target_dim:  1\n",
      "Params-total_dim:  2\n",
      "Prediction-W:  Tensor(\"Reshape:0\", shape=(1, 1), dtype=float32)\n",
      "Prediction-b:  Tensor(\"strided_slice_1:0\", shape=(), dtype=float32)\n",
      "error-self._error:  Tensor(\"mean_squared_error/value:0\", shape=(), dtype=float32)\n",
      "optimize-self._optimize:  name: \"GradientDescent\"\n",
      "op: \"NoOp\"\n",
      "input: \"^GradientDescent/update_params/ApplyGradientDescent\"\n",
      "\n",
      "gradients-self._gradients [<tf.Tensor 'gradients_1/AddN:0' shape=(2,) dtype=float32>]\n",
      "hessians-self._hessians:  [<tf.Tensor 'Reshape_2:0' shape=(2, 2) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "R = 1\n",
    "num_train_points = X_data.shape[0]\n",
    "\n",
    "tf.reset_default_graph()\n",
    "#tf.compat.v1.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder(dtype=tf.float32, shape=(None, 1))\n",
    "y_true = tf.placeholder(dtype=tf.float32, shape=(None, 1))\n",
    "model = LinearModel(x, y_true)\n",
    "train_op = model.optimize\n",
    "loss_op = model.error\n",
    "param_op = model.params\n",
    "gradient_op = model.gradients\n",
    "hessian_op = model.hessians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "accomplished-internship",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-23 11:46:52.346953: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-06-23 11:46:52.346995: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-06-23 11:46:52.347021: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (pnans): /proc/driver/nvidia/version does not exist\n",
      "2022-06-23 11:46:52.347368: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init_op:  name: \"init\"\n",
      "op: \"NoOp\"\n",
      "input: \"^params/Assign\"\n",
      "\n",
      "x, y_true:  Tensor(\"Placeholder:0\", shape=(?, 1), dtype=float32) Tensor(\"Placeholder_1:0\", shape=(?, 1), dtype=float32)\n",
      "r:  0  s_test_j:  [56.27774  17.586794] \n",
      "\n",
      "hess_param:  [50.  2.]\n",
      "hess_param:  [40.5  2. ]\n",
      "hess_param:  [32.  2.]\n",
      "hess_param:  [24.5  2. ]\n",
      "hess_param:  [18.  2.]\n",
      "hess_param:  [12.5  2. ]\n",
      "hess_param:  [8. 2.]\n",
      "hess_param:  [4.5 2. ]\n",
      "hess_param:  [2. 2.]\n",
      "hess_param:  [0.5 2. ]\n",
      "hess_param:  [0. 2.]\n",
      "hess_param:  [0.5 2. ]\n",
      "hess_param:  [2. 2.]\n",
      "hess_param:  [4.5 2. ]\n",
      "hess_param:  [8. 2.]\n",
      "hess_param:  [12.5  2. ]\n",
      "hess_param:  [18.  2.]\n",
      "hess_param:  [24.5  2. ]\n",
      "hess_param:  [32.  2.]\n",
      "hess_param:  [40.5  2. ]\n",
      "s_test:  [1.09140359e+22 1.09140359e+22]\n",
      "grad_param:  [-93.39996   18.679993]\n",
      "importance_last:  8.154964439321624e+23\n",
      "grad_param:  [ 568.0373   -126.230515]\n",
      "importance_last:  -4.821895042734913e+24\n",
      "grad_param:  [-74.50485   18.626213]\n",
      "importance_last:  6.098614754240534e+23\n",
      "grad_param:  [-63.755783  18.215939]\n",
      "importance_last:  4.970234986450888e+23\n",
      "grad_param:  [-56.28266   18.760887]\n",
      "importance_last:  4.0951399227282e+23\n",
      "grad_param:  [-45.603172  18.241268]\n",
      "importance_last:  2.9862880457400428e+23\n",
      "grad_param:  [-36.703094  18.351547]\n",
      "importance_last:  2.0028944571353668e+23\n",
      "grad_param:  [-27.233603  18.155735]\n",
      "importance_last:  9.907617202663532e+22\n",
      "grad_param:  [-18.030117  18.030117]\n",
      "importance_last:  -0.0\n",
      "grad_param:  [-8.984467 17.968933]\n",
      "importance_last:  -9.805679064694695e+22\n",
      "grad_param:  [ 0.       17.659016]\n",
      "importance_last:  -1.9273113111398323e+23\n",
      "grad_param:  [ 8.820074 17.640148]\n",
      "importance_last:  -2.8878781593189878e+23\n",
      "grad_param:  [17.860506 17.860506]\n",
      "importance_last:  -3.8986040920131286e+23\n",
      "grad_param:  [26.92788 17.95192]\n",
      "importance_last:  -4.8981973700064686e+23\n",
      "grad_param:  [35.805763 17.902882]\n",
      "importance_last:  -5.861780791032336e+23\n",
      "grad_param:  [-493.54553 -197.41821]\n",
      "importance_last:  7.541203131193803e+24\n",
      "grad_param:  [52.97307 17.65769]\n",
      "importance_last:  -7.708666327363366e+23\n",
      "grad_param:  [61.289986 17.511425]\n",
      "importance_last:  -8.600414263766921e+23\n",
      "grad_param:  [69.011185 17.252796]\n",
      "importance_last:  -9.41488185464287e+23\n",
      "grad_param:  [77.31744  17.181652]\n",
      "importance_last:  -1.0313664436426932e+24\n",
      "End of iter\n",
      "Loss: [77.32384904]\n"
     ]
    }
   ],
   "source": [
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    print(\"init_op: \",init_op)\n",
    "    for e in  range(EPOCHS):\n",
    "        fd = {x: X_data, y_true: Y_data}\n",
    "        if e == 0: print(\"x, y_true: \", x, y_true)\n",
    "        _, loss_epoch = sess.run([train_op, loss_op], feed_dict = fd)\n",
    "    p = sess.run(param_op)\n",
    "    s_test = 0\n",
    "    for r in range(R):\n",
    "        v = sess.run(gradient_op, feed_dict = {x:X_test, y_true:Y_test})[0]\n",
    "        s_test_j = v\n",
    "        print(\"r: \",r, \" s_test_j: \",s_test_j, \"\\n\")\n",
    "        for j in  range(num_train_points):\n",
    "            fd = {x:X_data[j].reshape((-1,1)), y_true:Y_data[j].reshape((-1,1))}\n",
    "            hess_param = sess.run(hessian_op, feed_dict = fd)[0]\n",
    "            hess_param = np.diag(hess_param)\n",
    "            print(\"hess_param: \",hess_param)\n",
    "            s_test_j = v + np.matmul((np.identity(2)-hess_param),s_test_j)\n",
    "        s_test += s_test_j\n",
    "    s_test = s_test/R\n",
    "    print(\"s_test: \",s_test)\n",
    "    importance = []\n",
    "    for j in  range(num_train_points):\n",
    "        fd = {x:X_data[j].reshape((-1,1)), y_true:Y_data[j].reshape((-1,1))}\n",
    "        grad_param = sess.run(gradient_op, feed_dict = fd)[0]\n",
    "        print(\"grad_param: \", grad_param)\n",
    "        importance.append(-np.matmul(s_test,grad_param))\n",
    "        print(\"importance_last: \", importance[-1])\n",
    "    print(\"End of iter\")\n",
    "importance = np.asarray(importance)\n",
    "print('Loss: {}'.format(((p[0]*X_test+p[1]-Y_test)**2)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "initial-walter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.15496444e+23, -4.82189504e+24,  6.09861475e+23,  4.97023499e+23,\n",
       "        4.09513992e+23,  2.98628805e+23,  2.00289446e+23,  9.90761720e+22,\n",
       "       -0.00000000e+00, -9.80567906e+22, -1.92731131e+23, -2.88787816e+23,\n",
       "       -3.89860409e+23, -4.89819737e+23, -5.86178079e+23,  7.54120313e+24,\n",
       "       -7.70866633e+23, -8.60041426e+23, -9.41488185e+23, -1.03136644e+24])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technical-directive",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EPOCHS = 100\n",
    "# R = 200\n",
    "# num_train_points = X_data.shape[0]\n",
    "\n",
    "# tf.reset_default_graph()\n",
    "# #tf.compat.v1.reset_default_graph()\n",
    "\n",
    "# x = tf.placeholder(dtype=tf.float32, shape=(None, 1))\n",
    "# y_true = tf.placeholder(dtype=tf.float32, shape=(None, 1))\n",
    "# model = LinearModel(x, y_true)\n",
    "# train_op = model.optimize\n",
    "# loss_op = model.error\n",
    "# param_op = model.params\n",
    "# gradient_op = model.gradients\n",
    "# hessian_op = model.hessians\n",
    "\n",
    "# init_op = tf.global_variables_initializer()\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(init_op)\n",
    "#     for e in  range(EPOCHS):\n",
    "#         fd = {x: X_data, y_true: Y_data}\n",
    "#         _, loss_epoch = sess.run([train_op, loss_op], feed_dict = fd)\n",
    "#     p = sess.run(param_op)\n",
    "#     s_test = 0\n",
    "#     for r in  range(R):\n",
    "#         v = sess.run(gradient_op, feed_dict = {x:X_test, y_true:Y_test})[0]\n",
    "#         s_test_j = v\n",
    "#         for j in  range(num_train_points):\n",
    "#             fd = {x:X_data[j].reshape((-1,1)), y_true:Y_data[j].reshape((-1,1))}\n",
    "#             hess_param = sess.run(hessian_op, feed_dict = fd)[0]\n",
    "#             hess_param = np.diag(hess_param)\n",
    "#             s_test_j = v + np.matmul((np.identity(2)-hess_param),s_test_j)\n",
    "#         s_test += s_test_j\n",
    "#     s_test = s_test/R\n",
    "#     importance = []\n",
    "#     for j in  range(num_train_points):\n",
    "#         fd = {x:X_data[j].reshape((-1,1)), y_true:Y_data[j].reshape((-1,1))}\n",
    "#         grad_param = sess.run(gradient_op, feed_dict = fd)[0]\n",
    "#         importance.append(-np.matmul(s_test,grad_param))\n",
    "\n",
    "# importance = np.asarray(importance)\n",
    "# print('Loss: {}'.format(((p[0]*X_test+p[1]-Y_test)**2)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mature-sculpture",
   "metadata": {},
   "outputs": [],
   "source": [
    "hess_param.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "discrete-delaware",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 258,
       "width": 359
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = plt.cm.get_cmap('RdYlBu')\n",
    "sc = plt.scatter(X_data.flatten(), Y_data.flatten(), label='train',c=-importance, cmap=cm)\n",
    "plt.scatter(X_test.flatten(), Y_test.flatten(),marker='+',label='test',c='r')\n",
    "plt.plot(X_data, p[0]*X_data+p[1])\n",
    "plt.colorbar(sc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "pleasant-horse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.821895042734913e+24"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(-importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "established-gather",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-7.541203131193803e+24"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(-importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "martial-oxygen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-7.541203131193803e+24"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-importance[-5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleased-stranger",
   "metadata": {},
   "source": [
    "## Influence Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noble-baltimore",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# Gets number of 7 and 1 labels in MNIST\n",
    "num_test = len(np.argwhere(y_test == 7)) + len(np.argwhere(y_test == 1))\n",
    "# Creating an empty array of blank data, with all labels being 1\n",
    "test = np.zeros((num_test, 784))\n",
    "test_label = np.zeros((num_test, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-feature",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "for i in  range(len(x_test)):\n",
    "    if y_test[i] == 7:\n",
    "        test[count] += (x_test[i] / np.linalg.norm(x_test[i])).reshape(784)\n",
    "        test_label[count] += np.array([1.0])\n",
    "        count += 1\n",
    "        if count == num_test:\n",
    "            break\n",
    "    elif y_test[i] == 1:\n",
    "        test[count] += (x_test[i] / np.linalg.norm(x_test[i])).reshape(784)\n",
    "        test_label[count] += np.array([0.0])\n",
    "        count += 1\n",
    "        if count == num_test:\n",
    "            break\n",
    "\n",
    "# We repeat this process on the training data\n",
    "num_train = len(np.argwhere(y_train == 7)) + len(np.argwhere(y_train == 1))\n",
    "data = np.zeros((num_train, 784))\n",
    "data_label = np.zeros((num_train, 1))\n",
    "count = 0\n",
    "for i in  range(len(x_train)):\n",
    "    if y_train[i] == 7:\n",
    "        data[count] += (x_train[i] / np.linalg.norm(x_train[i])).reshape(784)\n",
    "        data_label[count] += np.array([1.0])\n",
    "        count += 1\n",
    "        if count == num_train:\n",
    "            break\n",
    "    elif y_train[i] == 1:\n",
    "        data[count] += (x_train[i] / np.linalg.norm(x_train[i])).reshape(784)\n",
    "        data_label[count] += np.array([0.0])\n",
    "        count += 1\n",
    "        if count == num_train:\n",
    "            break\n",
    "\n",
    "# We're going to set a test index. This is an index within the training data\n",
    "# where we want to see how well our classifier performs on it\n",
    "test_index = 157\n",
    "plt.imshow(test[test_index].reshape(28, 28),cmap=\"inferno\", interpolation=\"nearest\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changed-season",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hinge_loss(logits, labels, dty=tf.float64):\n",
    "    margin = tf.multiply(tf.cast(labels, dtype=dty), logits)\n",
    "    log_loss = tf.maximum(tf.constant(0, dtype=dty), 1 - margin)\n",
    "    return tf.reduce_mean(log_loss)\n",
    "\n",
    "def smooth_hinge_loss(logits, labels, t=1e-3, dty=tf.float64):\n",
    "    margin = tf.multiply(tf.cast(labels, dtype=dty), logits)\n",
    "    exponents = (1 - margin) / t\n",
    "    max_elems = tf.maximum(exponents, tf.zeros_like(exponents))\n",
    "    log_loss = t * (max_elems + tf.log(tf.exp(exponents - max_elems) + tf.exp(tf.zeros_like(exponents) - max_elems)))\n",
    "    return tf.reduce_mean(log_loss)\n",
    "\n",
    "def get_accuracy_op(logits, labels, sigmoid=True, dty=tf.float64):\n",
    "    if sigmoid:\n",
    "        correct_prediction = tf.equal(tf.cast(L > 0.5, tf.int32), tf.cast(labels, tf.int32))\n",
    "        accuracy = tf.reduce_sum(tf.cast(correct_prediction, tf.int32))\n",
    "        return accuracy / tf.shape(labels)[0]\n",
    "    else:\n",
    "        preds = tf.sign(logits)\n",
    "        correct = tf.reduce_sum(tf.cast(tf.equal(preds, tf.cast(labels, dty)), tf.int32))\n",
    "        return correct / tf.shape(labels)[0]\n",
    "\n",
    "def hessian_vector_product(ys, xs, v, do_not_sum_up=True):\n",
    "    # Validate the input\n",
    "    length = len(xs)\n",
    "    if  len(v) != length:\n",
    "        raise  ValueError(\"xs and v must have the same length.\")\n",
    "    # First backprop\n",
    "    grads = tf.gradients(ys, xs)\n",
    "    # grads = xs\n",
    "    assert  len(grads) == length\n",
    "    elemwise_products = [\n",
    "        tf.multiply( grad_elem, tf.stop_gradient(v_elem)) for grad_elem, v_elem in  zip(grads, v) if grad_elem is  not  None\n",
    "    ]\n",
    "    # math_ops.multiply( grad_elem, array_ops.stop_gradient(v_elem)) for grad_elem, v_elem in  zip(grads, v) if grad_elem is  not  None\n",
    "    # Second backprop\n",
    "    if do_not_sum_up:\n",
    "        seperate = []\n",
    "        for i in  range(length):\n",
    "            seperate.append(tf.gradients(elemwise_products[i], xs[i])[0])\n",
    "        grads_with_none = seperate\n",
    "    else:\n",
    "        grads_with_none = tf.gradients(elemwise_products, xs)\n",
    "    return_grads = [\n",
    "        grad_elem if grad_elem is  not  None  else tf.zeros_like(x) for x, grad_elem in  zip(xs, grads_with_none)\n",
    "    ]\n",
    "    return return_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intellectual-birthday",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "nb_clases = 1\n",
    "dty = tf.float64\n",
    "scale = 1e0\n",
    "damping = 1e-2\n",
    "\n",
    "I = tf.eye(784, dtype=dty)\n",
    "we = {}\n",
    "we[0] = 784 * 1\n",
    "w1 = tf.get_variable(\"w1\", [we[0]], initializer=tf.initializers.truncated_normal, dtype=dty)\n",
    "w1 = w1 / tf.norm(w1)\n",
    "w1 = w1 / tf.constant(1e6, dtype=dty)\n",
    "params = [w1]\n",
    "\n",
    "Hess = tf.placeholder(dty, shape=[w1.get_shape()[0], w1.get_shape()[0]], name=\"inverse\")\n",
    "cur_in = tf.placeholder(dty, shape=[w1.get_shape()[0], w1.get_shape()[0]], name=\"inverse\")\n",
    "v_cur_est = [tf.placeholder(dty, shape=a.get_shape(), name=\"v_cur_est\" + str(i)) for i, a in  enumerate(params)]\n",
    "hessian_vector_val_place = [tf.placeholder(dty, shape=a.get_shape()[0], name=\"hessian_vector_val_place\" + str(i)) for i, a in  enumerate(params)]\n",
    "Test = [tf.placeholder(dty, shape=a.get_shape(), name=\"v_cur_est\" + str(i)) for i, a in  enumerate(params)]\n",
    "\n",
    "X = tf.placeholder(dty, [None, 784], name=\"X\")\n",
    "Y = tf.placeholder(dty, [None, nb_clases], name=\"Y\")\n",
    "L = tf.matmul(X, tf.reshape(w1, [-1, 1]))\n",
    "L = tf.nn.sigmoid(L)\n",
    "\n",
    "Z = tf.placeholder(dty, [None, 784], name=\"Z\")\n",
    "Y_of_Z_train = tf.placeholder(dty, [None, nb_clases], name=\"Y_of_Z_train\")\n",
    "L_Z = tf.matmul(Z, tf.reshape(w1, [-1, 1]))\n",
    "L_Z = tf.nn.sigmoid(L_Z)\n",
    "\n",
    "Z_test = tf.placeholder(dty, [None, 784], name=\"Z_test\")\n",
    "Y_test = tf.placeholder(dty, [None, nb_clases], name=\"Y_test\")\n",
    "L_test = tf.matmul(Z_test, tf.reshape(w1, [-1, 1]))\n",
    "L_test = tf.nn.sigmoid(L_test)\n",
    "\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(L + 1e-6) + (1 - Y) * tf.log(1 - L + 1e-6), 1))\n",
    "cost += damping * tf.nn.l2_loss(params) # gradient vanishing\n",
    "\n",
    "upweighting_loss = tf.reduce_mean(-tf.reduce_sum(Y_of_Z_train * tf.log(L_Z + 1e-6) + (1 - Y_of_Z_train) * tf.log(1 - L_Z + 1e-6), 1))\n",
    "upweighting_loss += damping * tf.nn.l2_loss(params) # gradient vanishing\n",
    "\n",
    "Test_loss = tf.reduce_mean(-tf.reduce_sum(Y_test * tf.log(L_test + 1e-6) + (1 - Y_test) * tf.log(1 - L_test + 1e-6), 1))\n",
    "Test_loss += damping * tf.nn.l2_loss(params) # gradient vanishing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tough-bearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grads\n",
    "test_grad = tf.gradients(Test_loss, params)\n",
    "train_grad = tf.gradients(upweighting_loss, params)\n",
    "\n",
    "# Hessians\n",
    "true_hess = tf.hessians(cost, params)\n",
    "\n",
    "# H dot v\n",
    "hessian_vector_val = hessian_vector_product(cost, params, v_cur_est, True)\n",
    "\n",
    "# H inverse\n",
    "estimation_IHVP = [ g + cur_e - HV / scale for g, HV, cur_e in  zip(Test, hessian_vector_val, v_cur_est)]\n",
    "estimation_inverse = (I + cur_in - tf.matmul(Hess, cur_in) / scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "severe-crime",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_op = tf.train.AdamOptimizer(1e-2).minimize(cost)\n",
    "accuracy = get_accuracy_op(L, Y)\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "  \n",
    "for epoch in range(1501):\n",
    "    for i in range(26):\n",
    "        batch_xs, batch_ys = (data[i * 500 : (i + 1) * 500], data_label[i * 500 : (i + 1) * 500])\n",
    "        _ = sess.run([train_op], feed_dict={X: batch_xs, Y: batch_ys})\n",
    "    if epoch % 500 == 0  and epoch > 0:\n",
    "        c = sess.run(accuracy, feed_dict={X: test, Y: test_label})\n",
    "        a = sess.run(accuracy, feed_dict={X: data, Y: data_label})\n",
    "        ccc = sess.run(cost, feed_dict={X: test, Y: test_label})\n",
    "        print(\"Train accuracy: \", a, \" Test accuracy: \", c, \" cost: \", ccc)\n",
    "print(\"sum of parameters: \", sess.run(tf.nn.l2_loss(params)).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tired-skill",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy Direct Inverse\n",
    "\n",
    "true_h = sess.run(true_hess[0], feed_dict={X: data, Y: data_label})\n",
    "inv = np.linalg.inv(true_h)\n",
    "np.linalg.norm(true_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selected-usage",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_estimate = sess.run(I)\n",
    "#start_time = time.time()\n",
    "for j in  range(5001):\n",
    "    cur_estimate = sess.run(estimation_inverse, feed_dict={Hess: true_h, cur_in: cur_estimate})\n",
    "inverse = cur_estimate / scale\n",
    "#duration = time.time() - start_time\n",
    "#print(\"Inverse Hessian by Lissa: took %s minute %s sec\" % (duration // 60, duration % 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elder-walker",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Lissa Identity Error: \", abs(np.dot(true_h, inverse) - np.eye(784)).sum())\n",
    "print(\"Numpy Identity Error: \", abs(np.dot(true_h, inv) - np.eye(784)).sum())\n",
    "print(\"Inverse Error: \", abs(inverse - inv).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imported-symbol",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_val = sess.run(\n",
    "    test_grad,\n",
    "    feed_dict={\n",
    "        Z_test: test[test_index].reshape((1, 784)),\n",
    "        Y_test: test_label[test_index].reshape((1, 1)),\n",
    "    },\n",
    ")\n",
    "IHVP = np.dot(test_val[0], inv)\n",
    "# start_time = time.time()\n",
    "cur_estimate = test_val.copy()\n",
    "feed1 = {place: cur for place, cur in zip(Test, test_val)}\n",
    "for j in range(5001):\n",
    "    feed2 = {place: cur for place, cur in zip(v_cur_est, cur_estimate)}\n",
    "    r = np.random.randint(len(data), size=[1024])\n",
    "    cur_estimate = sess.run(\n",
    "        estimation_IHVP,\n",
    "        feed_dict={\n",
    "            X: data[r],\n",
    "            Y: data_label[r],\n",
    "            **feed1,\n",
    "            **feed2,\n",
    "        },\n",
    "    )\n",
    "    if j % 2500 == 0  and j > 0:\n",
    "        print(cur_estimate[0][0])\n",
    "inverse_hvp = [b / scale for b in cur_estimate]\n",
    "# duration = time.time() - start_time\n",
    "# print(\"Inverse HVP by HVPs+Lissa: took %s minute %s sec\" % (duration // 60, duration % 60))\n",
    "print(abs(IHVP - inverse_hvp[0]).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggressive-termination",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = time.time()\n",
    "\n",
    "val_lissa = []\n",
    "for i in range(num_train):\n",
    "    if data_label[i][0] == test_label[test_index][0]:\n",
    "        train_grad_loss_val = sess.run(\n",
    "            train_grad,\n",
    "            feed_dict={\n",
    "                Z: data[i].reshape((1, 784)),\n",
    "                Y_of_Z_train: data_label[i].reshape((1, 1)),\n",
    "            },\n",
    "        )\n",
    "        val_lissa.append([i, np.dot(np.concatenate(inverse_hvp), np.concatenate(train_grad_loss_val))])\n",
    "# duration = time.time() - s\n",
    "# print(\"Multiplying by %s train examples took %s minute %s sec\" % (1, duration // 60, duration % 60))\n",
    "val_lissa = sorted(val_lissa, key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "starting-column",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = time.time()\n",
    "val = []\n",
    "for i in  range(num_train):\n",
    "    if data_label[i][0] == test_label[test_index][0]:\n",
    "        train_grad_loss_val = sess.run(\n",
    "            train_grad,\n",
    "            feed_dict={\n",
    "                Z: data[i].reshape((1, 784)),\n",
    "                Y_of_Z_train: data_label[i].reshape((1, 1)),\n",
    "            },\n",
    "        )\n",
    "        val.append([i, np.dot(IHVP, np.concatenate(train_grad_loss_val))])\n",
    "# duration = time.time() - s\n",
    "# print(\"Multiplying by %s train examples took %s minute %s sec\" % (1, duration // 60, duration % 60))\n",
    "val = sorted(val, key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defensive-complex",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Numpy IHVP\",\n",
    "      \"\\nMost Harmful Indexes\", [val[i][0] for i in  range(0, 6)],\n",
    "      \"\\nMost Helpful Indexes\", [val[i][0] for i in  range(-1, -7, -1)])\n",
    "print(\"Lissa IHVP\",\n",
    "      \"\\nMost Harmful Indexes\", [val_lissa[i][0] for i in  range(0, 6)],\n",
    "      \"\\nMost Helpful Indexes\", [val_lissa[i][0] for i in  range(-1, -7, -1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patent-trade",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 4))\n",
    "image_details = [\n",
    "    [\"Test_image\", test[test_index]],\n",
    "    [\"Harmful_image1\", data[val[0][0]]],\n",
    "    [\"Harmful_image2\", data[val[1][0]]],\n",
    "    [\"Harmful_image3\", data[val[2][0]]],\n",
    "    [\"Harmful_image4\", data[val[3][0]]],\n",
    "    [\"Harmful_image5\", data[val[4][0]]],\n",
    "    [\"Harmful_image6\", data[val[5][0]]]]\n",
    "for i in  range(1, 8):\n",
    "    ax = plt.subplot(1, 7, i)\n",
    "    plt.imshow(image_details[i-1][1].reshape(28, 28), cmap=\"inferno\", interpolation=\"nearest\")\n",
    "    ax.set_title(image_details[i-1][0])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technological-jaguar",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 4))\n",
    "\n",
    "image_details = [\n",
    "    [\"Test_image\", test[test_index]],\n",
    "    [\"Positive_image1\", data[val[-1][0]]],\n",
    "    [\"Positive_image2\", data[val[-2][0]]],\n",
    "    [\"Positive_image3\", data[val[-3][0]]],\n",
    "    [\"Positive_image4\", data[val[-4][0]]],\n",
    "    [\"Positive_image5\", data[val[-5][0]]],\n",
    "    [\"Positive_image6\", data[val[-6][0]]]]\n",
    "\n",
    "for i in  range(1, 8):\n",
    "    ax = plt.subplot(1, 7, i)\n",
    "    plt.imshow(image_details[i-1][1].reshape(28, 28), cmap=\"inferno\", interpolation=\"nearest\")\n",
    "    ax.set_title(image_details[i-1][0])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colonial-olive",
   "metadata": {},
   "source": [
    "## NN Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enclosed-mistake",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.losses import MeanSquaredLogarithmicError\n",
    "# TRAIN_DATA_PATH = '/content/sample_data/california_housing_train.csv'\n",
    "# TEST_DATA_PATH = '/content/sample_data/california_housing_test.csv'\n",
    "TARGET_NAME = 'median_house_value'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amazing-christian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = features, y_train = target\n",
    "train_data = pd.read_csv('california_housing_train.csv')\n",
    "test_data = pd.read_csv('california_housing_test.csv')\n",
    "x_train, y_train = train_data.drop(TARGET_NAME, axis=1), train_data[TARGET_NAME]\n",
    "x_test, y_test = test_data.drop(TARGET_NAME, axis=1), test_data[TARGET_NAME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposed-wrapping",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_datasets(x_train, x_test):\n",
    "    standard_scaler = StandardScaler()\n",
    "    \n",
    "    x_train_scaled = pd.DataFrame(standard_scaler.fit_transform(x_train), columns=x_train.columns)\n",
    "    x_test_scaled = pd.DataFrame(standard_scaler.transform(x_test), columns = x_test.columns)\n",
    "    \n",
    "    return x_train_scaled, x_test_scaled\n",
    "\n",
    "x_train_scaled, x_test_scaled = scale_datasets(x_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bibliographic-correlation",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_units1 = 160\n",
    "hidden_units2 = 480\n",
    "hidden_units3 = 256\n",
    "learning_rate = 0.01\n",
    "# Creating model using the Sequential in tensorflow\n",
    "def build_model_using_sequential():\n",
    "    model = Sequential([\n",
    "    Dense(hidden_units1, kernel_initializer='normal', activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(hidden_units2, kernel_initializer='normal', activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(hidden_units3, kernel_initializer='normal', activation='relu'),\n",
    "    Dense(1, kernel_initializer='normal', activation='linear')\n",
    "  ])\n",
    "    return model\n",
    "# build the model\n",
    "model = build_model_using_sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relevant-childhood",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "msle = MeanSquaredLogarithmicError()\n",
    "model.compile(\n",
    "    loss=msle, \n",
    "    optimizer=Adam(learning_rate=learning_rate), \n",
    "    metrics=[msle]\n",
    ")\n",
    "# train the model\n",
    "history = model.fit(\n",
    "    x_train_scaled.values, \n",
    "    y_train.values, \n",
    "    epochs=10, \n",
    "    batch_size=64,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporated-toner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, key):\n",
    "    plt.plot(history.history[key])\n",
    "    plt.plot(history.history['val_'+key])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(key)\n",
    "    plt.legend([key, 'val_'+key])\n",
    "    plt.show()\n",
    "# Plot the history\n",
    "plot_history(history, 'mean_squared_logarithmic_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comprehensive-electric",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test['prediction'] = model.predict(x_test_scaled)\n",
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broke-queen",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train.reshape(17000,1)\n",
    "#y_train.reshape((17000, 1))\n",
    "\n",
    "arr = y_train.values\n",
    "y_train = arr.reshape((17000, 1))\n",
    "\n",
    "\n",
    "arr = y_test.values\n",
    "y_test = arr.reshape((3000, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chinese-arcade",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaled = x_train_scaled.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "magnetic-alliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_scaled = x_test_scaled.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documented-interstate",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outdoor-geneva",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "robust-lambda",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "R = 2\n",
    "num_train_points = x_train_scaled.shape[0]\n",
    "\n",
    "tf.reset_default_graph()\n",
    "#tf.compat.v1.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder(dtype=tf.float32, shape=(None, 8))\n",
    "y_true = tf.placeholder(dtype=tf.float32, shape=(None, 1))\n",
    "\n",
    "model = LinearModel(x, y_true)\n",
    "train_op = model.optimize\n",
    "loss_op = model.error\n",
    "param_op = model.params\n",
    "gradient_op = model.gradients\n",
    "hessian_op = model.hessians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facial-foster",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init-Data:  Tensor(\"Placeholder:0\", shape=(?, 1), dtype=float32)\n",
    "# Init-Target:  Tensor(\"Placeholder_1:0\", shape=(?, 1), dtype=float32)\n",
    "# Prediction-data_dim:  1\n",
    "# Params-data_dim:  1\n",
    "# Params-target_dim:  1\n",
    "# Params-total_dim:  2\n",
    "# Prediction-W:  Tensor(\"Reshape:0\", shape=(1, 1), dtype=float32)\n",
    "# Prediction-b:  Tensor(\"strided_slice_1:0\", shape=(), dtype=float32)\n",
    "# error-self._error:  Tensor(\"mean_squared_error/value:0\", shape=(), dtype=float32)\n",
    "# optimize-self._optimize:  name: \"GradientDescent\"\n",
    "# op: \"NoOp\"\n",
    "# input: \"^GradientDescent/update_params/ApplyGradientDescent\"\n",
    "\n",
    "# gradients-self._gradients [<tf.Tensor 'gradients_1/AddN:0' shape=(2,) dtype=float32>]\n",
    "# hessians-self._hessians:  [<tf.Tensor 'Reshape_2:0' shape=(2, 2) dtype=float32>]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "figured-headline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EPOCHS = 100\n",
    "# R = 2\n",
    "# num_train_points = x_train_scaled.shape[0]\n",
    "\n",
    "# tf.reset_default_graph()\n",
    "# #tf.compat.v1.reset_default_graph()\n",
    "\n",
    "# x = tf.placeholder(dtype=tf.float32, shape=(None, 8))\n",
    "# y_true = tf.placeholder(dtype=tf.float32, shape=(None, 1))\n",
    "\n",
    "# model = LinearModel(x, y_true)\n",
    "# train_op = model.optimize\n",
    "# loss_op = model.error\n",
    "# param_op = model.params\n",
    "# gradient_op = model.gradients\n",
    "# hessian_op = model.hessians\n",
    "\n",
    "# init_op = tf.global_variables_initializer()\n",
    "# i = 0\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     print(\"Hello-1\", i)\n",
    "#     sess.run(init_op)\n",
    "#     for e in  range(EPOCHS):\n",
    "#         fd = {x: x_train_scaled, y_true: y_train}\n",
    "#         _, loss_epoch = sess.run([train_op, loss_op], feed_dict = fd)\n",
    "#     p = sess.run(param_op)\n",
    "#     s_test = 0\n",
    "#     for r in  range(R):\n",
    "#         print(\"Hello-2\", i, r)\n",
    "#         v = sess.run(gradient_op, feed_dict = {x:x_test_scaled, y_true:y_test})[0]\n",
    "#         s_test_j = v\n",
    "#         for j in  range(num_train_points):\n",
    "# #             print(x_train_scaled[j].reshape(1,-1).shape)\n",
    "# #             print(y_train[j])\n",
    "# #             break\n",
    "#             print(\"Hello-3\", i, j)\n",
    "#             fd = {x:x_train_scaled[j].reshape((1,-1)), y_true:y_train[j].reshape((-1,1))}\n",
    "#             hess_param = sess.run(hessian_op, feed_dict = fd)[0]\n",
    "#             hess_param = np.diag(hess_param)\n",
    "#             s_test_j = v + np.matmul((np.identity(9)-hess_param),s_test_j)\n",
    "#         s_test += s_test_j\n",
    "#     s_test = s_test/R\n",
    "#     importance = []\n",
    "#     for j in  range(num_train_points):\n",
    "#         print(\"Hello-4\", i, j)\n",
    "#         fd = {x:x_train_scaled[j].reshape((1,-1)), y_true:y_train[j].reshape((-1,1))}\n",
    "#         grad_param = sess.run(gradient_op, feed_dict = fd)[0]\n",
    "#         importance.append(-np.matmul(s_test,grad_param))\n",
    "#     i += 1\n",
    "\n",
    "# importance = np.asarray(importance)\n",
    "# print('Loss: {}'.format(((p[0]*x_test_scaled+p[1]-y_test)**2)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "european-kingston",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appreciated-firmware",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = plt.cm.get_cmap('RdYlBu')\n",
    "sc = plt.scatter(x_test_scaled.flatten(), y_test.flatten(), label='train',c=-importance, cmap=cm)\n",
    "plt.scatter(X_test.flatten(), Y_test.flatten(),marker='+',label='test',c='r')\n",
    "plt.plot(X_data, p[0]*X_data+p[1])\n",
    "plt.colorbar(sc)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
